{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**1.1 Computer vision**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why convolutional?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of parameters will be large in some tasks, which makes it difficult to get enough data to prevent over-fitting and also the competition requirements.  \n",
    "  \n",
    "The memory requirement to train too many parameters is a bit infeasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**Edge detection example**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to detect edges?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a 6 * 6 grayscale image:  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "3 & 0 & 1 & 2 & 7 & 4 \\\\\n",
    "1 & 5 & 8 & 9 & 3 & 1 \\\\\n",
    "2 & 7 & 2 & 5 & 1 & 3 \\\\\n",
    "0 & 1 & 3 & 1 & 7 & 8 \\\\\n",
    "4 & 2 & 1 & 6 & 2 & 8 \\\\\n",
    "2 & 4 & 5 & 2 & 3 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1, 2, 7, 4],\n",
       "       [1, 5, 8, 9, 3, 1],\n",
       "       [2, 7, 2, 5, 1, 3],\n",
       "       [0, 1, 3, 1, 7, 8],\n",
       "       [4, 2, 1, 6, 2, 8],\n",
       "       [2, 4, 5, 2, 3, 9]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([\n",
    "    [3, 0, 1, 2, 7, 4],\n",
    "    [1, 5, 8, 9, 3, 1],\n",
    "    [2, 7, 2, 5, 1, 3],\n",
    "    [0, 1, 3, 1, 7, 8],\n",
    "    [4, 2, 1, 6, 2, 8],\n",
    "    [2, 4, 5, 2, 3, 9]\n",
    "])\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to detect edges, let's say vertical edges in this image, what you can do is construct a 3 * 3 matrix (a **filter** or a **kernel**). Here the filter is constructed like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0, -1],\n",
       "       [ 1,  0, -1],\n",
       "       [ 1,  0, -1]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_v = np.array([\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "filter_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you're going to do is take the 6 * 6 image and **convolve** it with the 3 * 3 filter. The convolution operation is denoted by **\\***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the output of this convolution operator is a 4 * 4 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution operation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **M[0][0]** element in the resulting matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 1]   [ 1  0 -1]\n",
      "[1 5 8] * [ 1  0 -1] = -5\n",
      "[2 7 2]   [ 1  0 -1]\n"
     ]
    }
   ],
   "source": [
    "def convolution(A, filter_, row, col):\n",
    "    print(A[row, col:col+3], \" \", filter_[0])\n",
    "    print(A[row + 1, col:col + 3], \"*\", filter_[1], \"=\", np.sum(A[row:row+3, col:col+3] * filter_))\n",
    "    print(A[row + 2, col:col + 3], \" \", filter_[2])\n",
    "    \n",
    "convolution(A, filter_v, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **M[0][1]** one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]   [ 1  0 -1]\n",
      "[5 8 9] * [ 1  0 -1] = -4\n",
      "[7 2 5]   [ 1  0 -1]\n"
     ]
    }
   ],
   "source": [
    "convolution(A, filter_v, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **M[1][0]** one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 8]   [ 1  0 -1]\n",
      "[2 7 2] * [ 1  0 -1] = -10\n",
      "[0 1 3]   [ 1  0 -1]\n"
     ]
    }
   ],
   "source": [
    "convolution(A, filter_v, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How it works to detect the vertical edge?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 10, 10,  0,  0,  0],\n",
       "       [10, 10, 10,  0,  0,  0],\n",
       "       [10, 10, 10,  0,  0,  0],\n",
       "       [10, 10, 10,  0,  0,  0],\n",
       "       [10, 10, 10,  0,  0,  0],\n",
       "       [10, 10, 10,  0,  0,  0]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.c_[np.full((6, 3), 10), np.full((6, 3), 0)]\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(B, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition: light -> dark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the edge in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(filter_v, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "left: relatively bright  \n",
    "right: relatively dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "convolved = np.array([[ 0, 30, 30,  0],\n",
    "       [ 0, 30, 30,  0],\n",
    "       [ 0, 30, 30,  0],\n",
    "       [ 0, 30, 30,  0]])  # c * filter_\n",
    "plt.imshow(convolved, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions here seem a little bit wrong. It seems that the detected edge is a little bit fat. That's only because we're working with a pretty small img. If the img is large, the detection works well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convolved[0][1]: A[0:3, 1:4]  \n",
    "  \n",
    "The first col and second col of A[0:3, 1:4]: bright.  \n",
    "The thrid col of A[0:3, 1:4]  : dark.  \n",
    "Thus bright -> dark.  \n",
    "Thus convolved = 30 > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>1.3 More edgr detection</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reverse the shape of the transition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, 10, 10, 10],\n",
       "       [ 0,  0,  0, 10, 10, 10],\n",
       "       [ 0,  0,  0, 10, 10, 10],\n",
       "       [ 0,  0,  0, 10, 10, 10],\n",
       "       [ 0,  0,  0, 10, 10, 10],\n",
       "       [ 0,  0,  0, 10, 10, 10]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.c_[np.full((6, 3), 0), np.full((6, 3), 10)]\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(C, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition: dark -> light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "convolved_ = np.array([[ 0, 30, 30,  0],\n",
    "       [ 0, 30, 30,  0],\n",
    "       [ 0, 30, 30,  0],\n",
    "       [ 0, 30, 30,  0]]) * -1  # C * filter_\n",
    "plt.imshow(convolved_, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detect horizontal edges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_h = np.array([\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0],\n",
    "    [-1, -1, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(filter_h, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top: relatively bright  \n",
    "bottom: relatively dark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A more complex example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.c_[np.r_[np.full((3, 3), 10), np.full((3, 3), 0)], np.r_[np.full((3, 3), 0), np.full((3, 3), 10)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 10  0]   [1 1 1]\n",
      "[10 10  0] * [0 0 0] = 10\n",
      "[ 0  0 10]   [-1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "convolution(D, filter_h, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bright -> dark: two cols  \n",
    "dark -> bright: one col\n",
    "  \n",
    "Thus get a intermediate value, bright -> dark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning to detect edges**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treat the filter as a matrix containg 9 parameters. Use back prop to find the optimal parameters and make a good filter, which may not only able to detect horizontal and vertical edges, but other kinds of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**1.4 Padding**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that  \n",
    "  \n",
    "A.shape = n, n  \n",
    "filter.shape = f, f  \n",
    "  \n",
    "then  \n",
    "outcome_matrix.shape = n-f+1, n-f+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsides**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **shrinking output**: The img will shrink every time the convolution operator is applied.  \n",
    "2. **throwing away info from edges**: pixels on the corners or on the edges are used much less in the output so you're throwing away a lot of info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad the image.  \n",
    "  \n",
    "Pad the img with an additional border of one pixel all around the edges: 6 * 6 -> 8 * 8. Then after the convolution, get a 6 * 6 matrix.  \n",
    "  \n",
    "By convention pad with 0s.  \n",
    "  \n",
    "p: padding amount. 1 here.  \n",
    "After padding, the output size will be n+2p-f+1, n+2p-f+1\n",
    "  \n",
    "If you want, you can pad more pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valid and Same convolutions**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid: no convolution  \n",
    "same: pad so that output size is the same as the input size. $p = \\frac{f - 1}{2}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By convention, f is usually odd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**Strided convolutions**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from left to right:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>1 1 1</font> 1 1 1 1&nbsp;&nbsp;&nbsp;1 1 <font color=blue>1 1 1</font> 1 1  \n",
    "<font color=blue>1 1 1</font> 1 1 1 1&nbsp;&nbsp;&nbsp;1 1 <font color=blue>1 1 1</font> 1 1  \n",
    "<font color=blue>1 1 1</font> 1 1 1 1&nbsp;&nbsp;&nbsp;1 1 <font color=blue>1 1 1</font> 1 1  \n",
    "1 1 1 1 1 1 1&nbsp;&nbsp;&nbsp;1 1 1 1 1 1 1  \n",
    "1 1 1 1 1 1 1&nbsp;&nbsp;&nbsp;1 1 1 1 1 1 1  \n",
    "1 1 1 1 1 1 1&nbsp;&nbsp;&nbsp;1 1 1 1 1 1 1  \n",
    "1 1 1 1 1 1 1&nbsp;&nbsp;&nbsp;1 1 1 1 1 1 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from top to bottom:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>1 1 1</font> 1 1 1 1  \n",
    "<font color=blue>1 1 1</font> 1 1 1 1  \n",
    "<font color=blue>1 1 1</font> 1 1 1 1  \n",
    "1 1 1 1 1 1 1  \n",
    "1 1 1 1 1 1 1  \n",
    "1 1 1 1 1 1 1  \n",
    "1 1 1 1 1 1 1  \n",
    "  \n",
    "  \n",
    "  \n",
    "1 1 1 1 1 1 1  \n",
    "1 1 1 1 1 1 1  \n",
    "<font color=blue>1 1 1</font> 1 1 1 1  \n",
    "<font color=blue>1 1 1</font> 1 1 1 1  \n",
    "<font color=blue>1 1 1</font> 1 1 1 1  \n",
    "1 1 1 1 1 1 1  \n",
    "1 1 1 1 1 1 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s: stride. 2 here.  \n",
    "the output size: $\\lfloor \\frac{n + 2p - f}{s} + 1 \\rfloor$, $\\lfloor \\frac{n + \n",
    "2p - f}{s} + 1 \\rfloor$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technical note on cross-correlation vs. convolution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The course skipped the mirroring operation. Technically, what's really doing in the videos is sometimes called cross-correlation instead of convolution.But in dl literature, by convention, we just call this a convolution operation. By convention in machine learning, we usually do not bother with this flipping operation. The mirroring operation is not necessary in neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**1.6 Convolutions over volumnes**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RGB img for example:  \n",
    "6 * 6 * 3 (height * width * number of channels)  \n",
    "  \n",
    "And the filter should be:  \n",
    "3 * 3 * 3 (height * width * number of channels)  \n",
    "  \n",
    "The number of channels (also called the dpeth) in the img must match the number of channels in the filter.  \n",
    "  \n",
    "The output: 4 * 4 * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to compute?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the case of 2d. M[0][0]: 27 numbers * numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can this do?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are to detect vertical edges in the red channels of the img, the red channel of the filter can be:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "  \n",
    "And the grean and blue channels all 0s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't care what color it is, to detect vertical edges we can make three channels all the same as the red channel matrix above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple filters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to detect vertical, horizontal or other kinds of edges at the same time, we can use multiple edges.  \n",
    "  \n",
    "Stack outputs of every filters together to form an outcome with multiple channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The img: n, n, $n_c$ (the number of channels)  \n",
    "The filter: f, f, $n_c$  \n",
    "Outcome: n - f + 1, n - f + 1, $n_c^{'}$ (the number of filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**1.7 One layer of a convolutional network**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input: 6, 6, 3  \n",
    "filter1: 3, 3, 3  \n",
    "filter2: 3, 3, 3  \n",
    "  \n",
    "for the outcome of filter1: add a b1, and Relu(outcome1 + b1)  \n",
    "for the outcome of filter2: add a b2, and Relu(outcome2 + b2)  \n",
    "  \n",
    "And stack the two matrices together we get a 4, 4, 2 output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that  \n",
    "$Z^{[1]} = W^{[1]} a^{[0]} + b^{[1]}$  \n",
    "$a^{[1]} = g(Z^{[1]})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input here: $a^{[0]}$  \n",
    "The filters: $W^{[1]}$  \n",
    "outcome + b: $Z^{[1]}$  \n",
    "Relu(): g()  \n",
    "stacked outcome: $a^{[1]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of parameters in a layer containing filters is determined by the number of **filters** (input features), no matter how large the input data is. It's a property of convolutional neural nets that **makes them less prone to over fitting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some notation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If layer $l$ is a convolutional layer:  \n",
    "\n",
    "Input:$n^{[l-1]}_H * n^{[l-1]}_W * n^{[l-1]}_c$  \n",
    "Output:$n^{[l]}_H * n^{[l]}_W * n^{[l]}_c$\n",
    "\n",
    "$f^{[l]}$ = filter size  \n",
    "$p^{[l]}$ = padding  \n",
    "$s^{[l]}$ = stride  \n",
    "$n^{[l]}_c$ = number of filters  \n",
    "  \n",
    "Each filter is: $f^{[l]} * f^{[l]} * n^{[l-1]}_c$  \n",
    "Activations: $a^{[l]}$ -> $n^{[l]}_H * n^{[l]}_W * n^{[l]}_c$ (one example), $m * n^{[l]}_H * n^{[l]}_W * n^{[l]}_c$ (m examples)  \n",
    "Weight: $f^{[l]} * f^{[l]} * n^{[l-1]}_c * n^{[l]}_c$  \n",
    "bias: $n^{[l]}_c$ or (1, 1, 1, $n^{[l]}_c$)  \n",
    "  \n",
    "$n^{[l]}_H = \\lfloor \\frac{n^{[l-1]}_W + 2p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\rfloor$  \n",
    "$n^{[l]}_W = \\lfloor \\frac{n^{[l-1]}_H + 2p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\rfloor$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**1.8 A simple convolutional network example**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of the convomutional part: unroll all numbers in the output into a very long vector, so that you just have one long vector to feed into soft max, into logistic reg, in order to make a prediction for the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically you start out with larger images, and then the height and width will stay the same for a while and gradually trend down as you go deeper in your networks, whereas the number of channels will generally increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of layer in a convolutional network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a typical ConvNet, there are usually three types of layers. One is the **conv layer**, notated as **CONV**. It turns out that there are two other common types of layers that you have not seen yet, a **pooling layer** (**POOL**) and a **fully connected layer** (**FC**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**1.9 Pooling layers**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be used to reduce the size of the repr of neural networks to speed up computation  \n",
    "make some of the features it detects a bit more robust "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max pooling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a 4 * 4 matrix:  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "1 & 3 & 2 & 1 \\\\\n",
    "2 & 9 & 1 & 1 \\\\\n",
    "1 & 3 & 2 & 3 \\\\\n",
    "5 & 6 & 1 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$  \n",
    "  \n",
    "The result of the max pooling will be a 2 * 2 matrix:  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "9 & 2 \\\\\n",
    "6 & 3 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$  \n",
    "  \n",
    "The M[0][0] in the output matrix comes from choosing the max from \n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "1 & 3 \\\\\n",
    "2 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "\n",
    "And M[0][1]\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's like we used a 2 * 2 filter with f = 2, s = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What it does**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the max operation does is so long as the feature is detected anywhere in one in one of these quadrants, it then remains preserved in the output of Max pooling. What the max operator does is really says, if this feature is detected anywhere in this filter, then keep a high number. But if this feature is not detected, maybe this feature does not exist in the upper right hand quadrant, then the max of all those numbers is still itself quite small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has a set of hyperparameters (f = 2 and s = 2 here), but there's actually nothing for gd to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d input**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will have the same dimension (3d for a 3d input). Use the first channel of the input matrix to get the first channel of the output matrix, and so on. If the input is 5 * 5 * 2, the output is 3 * 3 * 2, if f = 3 and s = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average pooling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the max, take the average. For the first example, M[0][0] will be 3.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**summary of pooling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;f: filter size  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;s: stride  \n",
    "  \n",
    "Size:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Intput: $n_H$ * $n_W$ * $n_c$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Output: $\\lfloor \\frac{n_H - f}{s} + 1 \\rfloor$ * $\\lfloor \\frac{n_W - f}{s} + 1 \\rfloor$ * $n_c$   \n",
    "  \n",
    "Max or average pooling.  \n",
    "  \n",
    "The common choice of hyperparameters: f = 2, s = 2. This has the effect of roughly shrinking the height and width by a factor of about two.  \n",
    "  \n",
    "No parameters to learn when implementing back prop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**1.10 Convolutional neural network example**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two conventions which are slightly in consistence about what you call a layer. One convention is that CONV + POOL is a layer, and the other is CONV a layer, and POOL a layer. When people report a number of layers in a neural network, usually people report just the number of layers that have weights, that have parameters, and because the pooling layer has no weights, has no parameters, only a few hyperparameters, the video uses the convention that treating the CONV and POOL together as a layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fully connected layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is just like a single neural network, is just a standard neural network where you have a weight matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**1.11 Why convolutions?**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than using all fully connected layers, CNN has mainly two advantages:  \n",
    "1. parameter sharing: A feature detector (such as a vertical edge detector) that's useful in one part of the image is probably useful in another part of the image.  \n",
    "2. sparsity of connections: In each layer, each output value depends only on a small number of inputs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost func of a CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the cost func of a logistic reg model:  \n",
    "$J = \\frac{1}{m} \\sum^m_{i=1} L(\\hat y^{(i)}, y^{(i)})$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
