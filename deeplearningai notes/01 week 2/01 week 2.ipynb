{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=3>2.1 Binary classification</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Some notations in the course**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(x, y)$: an instance / example.  \n",
    "For logistic regression, $x \\in R^{n_x}$, $y \\in \\{0, 1\\}$, where $n_x$ is the number of features$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$m$: the size of the data set.  \n",
    "If there are $m$ training examples: $\\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\cdots, (x^{(m)}, y^{(m)})\\}$  \n",
    "$m_{train}$:  \n",
    "the size of the training set.  \n",
    "$m_{test}$:  \n",
    "the size of the test set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized notation:  \n",
    "$X = [x^{(1)}, x^{(2)}, \\cdots, x^{(m)}]$, $n_x$ rows and $m$ columns. Each row represents a feature and each column represents an example.  \n",
    "$Y = [y^{(1)}, y^{(2)}, \\cdots, y^{(m)}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=3>2.2 Logistic Regression</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some notations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat y$: the prediction  \n",
    "$\\hat y = p(y = 1 | x)$: the probability of the chance that $y = 1$ given the input features $x$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we programmed neural networks, we'll usually keep the parameter $w$ and $b$ separate, where $b$ corresponds to an interceptor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $x$, want $\\hat y = p(y = 1 | x)$  \n",
    "  \n",
    "$x \\in R^{n_x}$, $0 \\leq \\hat y \\leq 1$  \n",
    "  \n",
    "Parameters:  \n",
    "$w \\in R^{n_x}$, $b \\in R$  \n",
    "  \n",
    "Output:  \n",
    "$\\hat y = \\sigma(w^T x + b) = \\sigma(z)$, where $z = w^T x + b$, and $\\sigma(z) = \\frac{1}{1 + e^{-z}}$  \n",
    "  \n",
    "More correctly:  \n",
    "$\\hat y^{(i)} = \\sigma(w^T x^{(i)} + b)$, where $\\sigma(z^{(i)}) = \\frac{1}{1 + e^{-z}} = \\frac{1}{1 + e^{-(w^T x^{(i)} + b)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the sigmoid function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=3>2.3 Logistic Regression cost function</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $(x^{(1)}, y^{(1)}), \\cdots, (x^{(m)}, y^{(m)})$, want $\\hat y^{(i)} \\approx y^{(i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $L(\\hat y^{(i)}) = \\frac{1}{2}(\\hat y - y)^2$ will not be used for logistic regression for that when optimizing the problem with gradient descent there will be multiple **local optima**.<font color=red># why?</font>  \n",
    "  \n",
    "Instead, we will use:  \n",
    "$L(\\hat y, y) = -(y log \\hat y + (1 - y) log (1 - \\hat y))$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some explanation:  \n",
    "When $y = 1$, let $L(\\hat y, y) = -log \\hat y$ as small as possible  \n",
    "-> $log \\hat y$ as large as possible  \n",
    "-> $log \\hat y = ln \\hat y$ here, which is an increasing function  \n",
    "-> $\\hat y$ as large as possible.\n",
    "  \n",
    "Since $0 \\leq \\hat y \\leq 1$, so that  \n",
    "$\\hat y$ close to 1 as much as possible.\n",
    "\n",
    "When $y = 0$, let $L(\\hat y, y) = -log (1 - \\hat y)$ as small as possible  \n",
    "-> let $log (1 - \\hat y)$ as large as possible  \n",
    "-> $log (1 - \\hat y) = ln (1 - \\hat y)$ here, which is an increasing function  \n",
    "-> $1 - \\hat y$ as large as possible  \n",
    "-> $- \\hat y$ as large as possible  \n",
    "-> $\\hat y$ as small as possible  \n",
    "  \n",
    "Since $0 \\leq \\hat y \\leq 1$, so that  \n",
    "$\\hat y$ close to 0 as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss func and cost func**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **loss func** is defined with respect to **a single training example**, it measures how well you're doing on a **single** training example.  \n",
    "  \n",
    "**The cost func** measures how well you're doing on the **entire** training set.**  \n",
    "$J(w, b) = \\frac{1}{m} \\sum^m_{i = 1} L(\\hat y^{(i)}, y^{(i)}) = -\\frac {1}{m} \\sum^m_{i = 1} [y^{(i)} log \\hat y^{(i)} + (1 - y^{(i)}) log (1 - \\hat y^{(i)})]$.  \n",
    "  \n",
    "Note that $J(w, b)$ here is a cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**2.4 Gradient Descent**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat {  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$w := w - \\alpha \\frac{\\partial J(w, b)}{dw}$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$b := b - \\alpha \\frac{\\partial J(w, b)}{db}$  \n",
    "}  \n",
    "\n",
    "It's the inner loop of the GD.  \n",
    "When writing code, the derivative term will be written as dw, db."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the derivative is greater than 0, $w$ will be decreased.  \n",
    "When the derivative is less than 0, $w$ will be increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**2.8 Derivatives with a Computation Graph**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some notations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dvar in the code you write will represent the derivative of the **final output** you care about such as J, sometimes the Last L, respect to the various **intermediate quantities** you're computing in your code.  \n",
    "  \n",
    "For example, $\\frac{dJ}{dv} = dv$, $\\frac{dJ}{da} = da$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**2.9 Logistic Regression Greadient descent**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**some notations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat y = a = \\sigma(z)$  \n",
    "$L(a, y) = -(y log a + (1 - y) log (1 - a))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression derivatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$da = -\\frac{y}{a} + \\frac{1 - y}{1 - a}$  \n",
    "$dz = a - y$  \n",
    "  \n",
    "$dw_1 = x_1 dz$  \n",
    "$dw_2 = x_2 dz$  \n",
    "$db = dz$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GD respect to a single example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat {  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$w_1 := w_1 - \\alpha dw_1$   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$w_2 := w_2 - \\alpha dw_2$   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$b := b - \\alpha db$  \n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when plugging in the derivatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat {  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$w_1 := w_1 - \\alpha x_1 dz$   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$w_2 := w_2 - \\alpha x_2 dz$   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$b := b - \\alpha dz$  \n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**2.10 Gradient descent on $m$ examples**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial}{\\partial w_1}J(w, b) = \\frac{1}{m} \\sum^m_{i = 1} \\frac{\\partial}{\\partial w^{(i)}_1} L(a^{(i)}, y^{(i)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GD for $m$ examples in one step**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// accumulators  \n",
    "J = 0, <font color=blue>dw1 = 0, dw2 = 0</font>, db = 0  \n",
    "  \n",
    "// over the training set, compute the derivatives respect to each training example  \n",
    "For i = 1 to m {   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;// forward prop  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$z^{(i)} = w^T x^{(i)} + b$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$a^{(i)} = \\sigma(z^{(i)})$  \n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;J += $-[y^{(i)}loga^{(i)} + (1 - y^{(i)}) log (1 - a^{(i)})]$  \n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;//back prop  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$dz^{(i)} = a^{(i)} - y^{(i)}$  \n",
    "<font color=blue>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$dw_1 += x^{(i)}_1 dz^{(i)}$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$dw_2 += x^{(i)}_2 dz^{(i)}$\n",
    "</font>  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$db += dz^{(i)}$  \n",
    "}  \n",
    "  \n",
    "// mean  \n",
    "J /= m  \n",
    "<font color=blue>\n",
    "dw_1 /= m  \n",
    "dw_2 /= m  \n",
    "</font>\n",
    "db /= m  \n",
    "  \n",
    "// GD  \n",
    "// a for loop will be needed to calculate the derivative of each feature  \n",
    "// if there are multiple features  \n",
    "$w_1 := w_1 - \\alpha \\cdot dw_1$   \n",
    "$w_2 := w_2 - \\alpha \\cdot dw_2$   \n",
    "$b := b - \\alpha \\cdot db$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two weaknesses.  \n",
    "  \n",
    "Two for loops. One for iterating over $m$ examples and the other for calculating the derivative of each example.  \n",
    "  \n",
    "Note that there are only two examples here thus a for loop is not needed to calculated the derivative of each feature. If there are multiple features, a for loop is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**2.11 Vectorization**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// accumulators  \n",
    "J = 0, <font color=blue>dw = np.zeros([$n_x$, 1])</font>, db = 0  \n",
    "  \n",
    "// over the training set, compute the derivatives respect to each training example  \n",
    "For i = 1 to m {   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;// forward prop  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$z^{(i)} = w^T x^{(i)} + b$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$a^{(i)} = \\sigma(z^{(i)})$  \n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;J += $-[y^{(i)}loga^{(i)} + (1 - y^{(i)}) log (1 - a^{(i)})]$  \n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;//back prop  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$dz^{(i)} = a^{(i)} - y^{(i)}$  \n",
    "<font color=blue> \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$dw += x^{(i)}dz^{(i)}$\n",
    "</font>  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$db += dz^{(i)}$  \n",
    "}  \n",
    "  \n",
    "// mean  \n",
    "J /= m  \n",
    "<font color=blue>\n",
    "dw /= m  \n",
    "</font>\n",
    "db /= m  \n",
    "  \n",
    "// GD  \n",
    "$w := w - \\alpha \\cdot dw$   \n",
    "$b := b - \\alpha \\cdot db$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**2.13 Vectorizing Logistic Regression**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement a vectorized implementation of the forward prop for all m training examples at the same time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "X &= [x^{(1)}, x^{(2)}, \\cdots, x^{(m)}] \\\\\n",
    "\\\\\n",
    "Z &= [z^{(1)}, z^{(2)}, \\cdots, z^{(m)}] \\\\\n",
    "&= w^T X + [b, b, \\cdots, b] \\\\\n",
    "&= [w^T x^{(1)} + b, w^T x^{(2)} + b, \\cdots, w^T x^{(m)} + b] \\\\\n",
    "\\\\\n",
    "A &= [a^{(1)}, a^{(2)}, \\cdots, a^{(m)}] = \\sigma(Z)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 >**2.14 Vectorizing Logistic Regression's Gradient Computation**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a vectorized implementation of the back prop**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "dZ &= [dz^{(1)}, dz^{(2)}, \\cdots, dz^{(m)}] \\\\\n",
    "&= A - Y \\\\\n",
    "&= [a^{(1)} - y^{(1)}, a^{(2)} - y^{(2)}, \\cdots, a^{(m)} - y^{(m)}] \\\\\n",
    "\\\\\n",
    "db &= \\frac{1}{m} \\sum^m_{i=1}dz^{(i)} \\\\\n",
    "&= \\frac{1}{m} np.sum(dZ) \\\\\n",
    "\\\\\n",
    "dW &= \\frac{1}{m}X \\cdot dZ^T \\\\\n",
    "&= \\frac{1}{m} [x^{(1)}, x^{(2)}, \\cdots, x^{(m)}]\n",
    "\\begin{bmatrix}\n",
    "dz^{(1)} \\\\\n",
    "dz^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "dz^{(n_x)} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&= \\frac{1}{m}\n",
    "\\begin{bmatrix}\n",
    "\\sum^m_{i=1} x^{(i)}_1 dz^{(1)} \\\\\n",
    "\\sum^m_{i=1} x^{(i)}_2 dz^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "\\sum^m_{i=1} x^{(i)}_m dz^{(m)} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "dw_1 \\\\\n",
    "dw_2 \\\\\n",
    "\\vdots \\\\\n",
    "dw_{n_x} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing Logistic Regression**\n",
    "(one loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// accumulators  \n",
    "J = 0, dw = np.zeros([$n_x$, 1]), db = 0  \n",
    "  \n",
    "// over the training set, compute the derivatives respect to each training example  \n",
    "<font color=blue>\n",
    "$Z = w^T X + b$  \n",
    "$A = \\sigma(Z)$  \n",
    "\n",
    "//back prop  \n",
    "$dZ = A - Y$  \n",
    "$dw = XdZ^T$  \n",
    "$db = np.sum(dZ)$\n",
    "</font>\n",
    "    \n",
    "// mean  \n",
    "dw /= m  \n",
    "db /= m  \n",
    "  \n",
    "// GD   \n",
    "<font color=blue>\n",
    "$w := w - \\alpha \\cdot dw$   \n",
    "$b := b - \\alpha \\cdot db$  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GD for 1000 loops**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i = 1 to m {\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;// accumulators  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;J = 0, dw = np.zeros([$n_x$, 1]), db = 0  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;// over the training set, compute the derivatives respect to each training &nbsp;&nbsp;&nbsp;&nbsp;example  \n",
    "<font color=blue>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$Z = w^T X + b$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$A = \\sigma(Z)$  \n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;//back prop  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$dZ = A - Y$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$dw = XdZ^T$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$db = np.sum(dZ)$\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;</font>\n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;// mean  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;dw /= m  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;db /= m  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;// GD   \n",
    "<font color=blue>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$w := w - \\alpha \\cdot dw$   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$b := b - \\alpha \\cdot db$  \n",
    "</font>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>**2.18 Explanation of logistic regression cost func**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(My understanding)  \n",
    "If the label of one example is 1, we want the evaluated probability $p(y = 1 | x)$ to be maximum. If the label of one example is 0, we want $p(y = 0 | x)$ to be maximum. Thus for an example, we want $p(y | x)$ to be maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Loss function (for one example)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat y = p(y = 1 | x)$  \n",
    "This equation means given an example x, the probability that $y = 1$.  \n",
    "  \n",
    "if $y = 1$, $p(y | x) = p(y = 1 | x) = \\hat y$  \n",
    "if $y = 0$, $p(y | x) = p(y = 0 | x) = 1 - p(y = 1 | x) = 1 - \\hat y$  \n",
    "  \n",
    "Take these two equations and summarize them into a single equation, we get:  \n",
    "$p(y | x) = {\\hat y}^y{(1 - \\hat y)}^{(1 - y)}$  \n",
    "  \n",
    "Our goal is $max\\{p(y | x)\\}$, and since $log x$ is an increasing function, we can then maximize $log p(y | x)$.  \n",
    "$max\\{log p(y | x)\\} \\\\= max \\{ylog \\hat y + (1 - y) log \\hat (1 - \\hat y)\\} \\\\= max\\{-L(\\hat y, y)\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost function (for multiple examples)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiple examples, we want $max${p(labels in the training set)} = $\\prod^m_{i=1} p(y^{(i)} | x^{(i)})$  \n",
    "  \n",
    "Similarly, we want  \n",
    "$max${p(labels in the training set)}  \n",
    "$= max\\{log \\prod^m_{i=1} p(y^{(i)} | x^{(i)})\\}\n",
    "\\\\= max\\{\\sum^m_{i=1} log p(y^{(i)} | x^{(i)})\\}\n",
    "\\\\= max\\{-L(\\hat y^{(i)}, y^{(i)})\\}\n",
    "\\\\= min \\sum^m_{i=1} L(\\hat y^{(i)}, y^{(i)})$\n",
    "\n",
    "For convenience, we make sure that our quantities are better scale (缩放), we just add a $\\frac{1}{m}$ which is an extra scaling factor here.\n",
    "  \n",
    "Thus $\\frac{1}{m}\\sum^m_{i=1} L(\\hat y^{(i)}, y^{(i)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(My understanding)  \n",
    "**Why classify according to the probability?**\n",
    "Say an expert on weather want to predict if tomorrow is rainy. He may evaluate the 降水確率 to predict. Here the kakuritsu is a kind of probability. If the kakuritsu is high, there is a high probability that tomorrow will be rainy. Here the classification task make a prediction that whether tomorrow is rainy, where sunny is a class and rainy is another class. And the prediction, or classification here is made according to the kakuritsu. If the kakuritsu is high, tomorrow will be classified as a rainy day. Thus thinking from our daili life, it's natual for a computer to make classification using probabilities. And calculating probabilities is kind of calculation, which computers are good at.  \n",
    "  \n",
    "**Why linear function works?**  \n",
    "For logistic regression we get one of the two classes with a step related to a linear function. How can we convert the outcome of the linear function into two classes, or for logistic regression, two values 0 or 1? Actually the classification is done by separating the real number set into two halves, one half represents a class and the other half represents the other class. For logistic regression, classes are determined by if the outcome calculated by the linear function is greater than 0. And the sigmoid function here is to map the outcomes calculated by the linear regresion into 0 or 1. Actually the classifier can work ,in a way, without the sigmoid function, but determine the class using the outcome of the linear function directly. If the outcome is greater than 0, the example belongs to a class. And if the outcome is less than 0, the example belongs to the other class. Therefore, what the linear function does is calculating the y for the corresponding example, which is in the real number set. And the outcome is used to classify according to some rules. Here the sigmoid function can be considered as a rule, this rule determines the outcome, which represents a specified example, belongs to which class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
